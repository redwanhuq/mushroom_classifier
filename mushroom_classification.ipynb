{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's been awhile since my last blog post but we've been busy with a big move from Houston to Brooklyn. The opportunities in New York City for data science and AI seem endless! I've also been spending some time putting to practice my newly acquired knowledge of machine learning by browsing through open datasets.\n",
    "\n",
    "One dataset that piqued my interest is the [mushroom dataset](http://archive.ics.uci.edu/ml/datasets/Mushroom?ref=datanews.io) from the UCI Machine Learning Repository describing different species from the genera *Agaricus* and *Lepiota*. The data are taken from The Audubon Society Field Guide to North American Mushrooms, which states \"there is no simple rule for determining the edibility of a mushroom\". Challenged by this bold claim, I  wanted to explore if a machine could succeed here. In addition to answering this question, this post explores some common issues in machine learning and how to use Python's go-to machine learning library, Scikit-learn, to address them.\n",
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (cross_val_score, GridSearchCV, \n",
    "                                     train_test_split, StratifiedShuffleSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Inspecting the dataset](#cell1)\n",
    "2. [Data wrangling](#cell2)\n",
    "3. [Training a model with the hold-out method](#cell3)\n",
    "4. [Using nested cross-validation to evaluate performance](#cell4)\n",
    "5. [Identifying the most influential features](#cell5)\n",
    "\n",
    "<a id=\"cell1\"></a>\n",
    "# 1. Inspecting the dataset\n",
    "Let's begin by loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1  2  3  4  5  6  7  8  9  ... 13 14 15 16 17 18 19 20 21 22\n",
       "0  p  x  s  n  t  p  f  c  n  k ...  s  w  w  p  w  o  p  k  s  u\n",
       "1  e  x  s  y  t  a  f  c  b  k ...  s  w  w  p  w  o  p  n  n  g\n",
       "2  e  b  s  w  t  l  f  c  b  n ...  s  w  w  p  w  o  p  n  n  m\n",
       "3  p  x  y  w  t  p  f  c  n  n ...  s  w  w  p  w  o  p  k  s  u\n",
       "4  e  x  s  g  f  n  f  w  b  k ...  s  w  w  p  w  o  e  n  a  g\n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training set, delimited by commas, into a DataFrame\n",
    "df = pd.read_table('data/agaricus-lepiota.data', delimiter=',', header=None)\n",
    "\n",
    "# Display the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      "0     8124 non-null object\n",
      "1     8124 non-null object\n",
      "2     8124 non-null object\n",
      "3     8124 non-null object\n",
      "4     8124 non-null object\n",
      "5     8124 non-null object\n",
      "6     8124 non-null object\n",
      "7     8124 non-null object\n",
      "8     8124 non-null object\n",
      "9     8124 non-null object\n",
      "10    8124 non-null object\n",
      "11    8124 non-null object\n",
      "12    8124 non-null object\n",
      "13    8124 non-null object\n",
      "14    8124 non-null object\n",
      "15    8124 non-null object\n",
      "16    8124 non-null object\n",
      "17    8124 non-null object\n",
      "18    8124 non-null object\n",
      "19    8124 non-null object\n",
      "20    8124 non-null object\n",
      "21    8124 non-null object\n",
      "22    8124 non-null object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 8124 training examples, each representing a single mushroom. The first column is the target variable containing the class labels, identifying whether the mushroom is poisonous or edible. The remaining columns are 22 discrete features that describe the mushroom in some observable way; their values are encoded by characters. For example, `gill size` is either broad (b) or narrow (n), and `veil color` can be brown (n), orange (o), white (w), or yellow (y). Each feature has numerous values so if you'd like to peruse the details you can find them in the [data description](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.names).\n",
    "\n",
    "Because the target variable contains discrete values, we'll need to train a classifier. But first, let's update the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = [\n",
    "    'class', 'cap shape', 'cap surface', 'cap color', 'bruised', 'odor',\n",
    "    'gill attachment', 'gill spacing', 'gill size', 'gill color', \n",
    "    'stalk shape', 'stalk root', 'stalk surface above ring',\n",
    "    'stalk surface below ring', 'stalk color above ring',\n",
    "    'stalk color below ring', 'veil type', 'veil color', 'ring number',\n",
    "    'ring type', 'spore print color', 'population', 'habitat'\n",
    "]\n",
    "\n",
    "# Update the column labels\n",
    "df.columns = column_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data description indicates that the feature `stalk root` has some missing values, denoted by `?`. In this analysis, we'll exclude any training example that has missing values for `stalk root`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['stalk root'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's pull out the features and the target variable, and place them in their own tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap shape</th>\n",
       "      <th>cap surface</th>\n",
       "      <th>cap color</th>\n",
       "      <th>bruised</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill attachment</th>\n",
       "      <th>gill spacing</th>\n",
       "      <th>gill size</th>\n",
       "      <th>gill color</th>\n",
       "      <th>stalk shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk surface below ring</th>\n",
       "      <th>stalk color above ring</th>\n",
       "      <th>stalk color below ring</th>\n",
       "      <th>veil type</th>\n",
       "      <th>veil color</th>\n",
       "      <th>ring number</th>\n",
       "      <th>ring type</th>\n",
       "      <th>spore print color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cap shape cap surface cap color bruised odor gill attachment gill spacing  \\\n",
       "0         x           s         n       t    p               f            c   \n",
       "1         x           s         y       t    a               f            c   \n",
       "2         b           s         w       t    l               f            c   \n",
       "3         x           y         w       t    p               f            c   \n",
       "4         x           s         g       f    n               f            w   \n",
       "\n",
       "  gill size gill color stalk shape   ...   stalk surface below ring  \\\n",
       "0         n          k           e   ...                          s   \n",
       "1         b          k           e   ...                          s   \n",
       "2         b          n           e   ...                          s   \n",
       "3         n          n           e   ...                          s   \n",
       "4         b          k           t   ...                          s   \n",
       "\n",
       "  stalk color above ring stalk color below ring veil type veil color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring number ring type spore print color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the features\n",
    "X = df.loc[:, df.columns != 'class']\n",
    "\n",
    "# Display the first five rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class\n",
       "0     p\n",
       "1     e\n",
       "2     e\n",
       "3     p\n",
       "4     e"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the target variable\n",
    "y = df['class'].to_frame()\n",
    "\n",
    "# Display the first five rows\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're here, let's take a look at how the two classes are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    3488\n",
       "p    2156\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there are vastly more training examples for edible mushrooms versus poisonous ones. We'll have to take this imbalance into account when training and evaluating the classifier.\n",
    "\n",
    "<a id=\"cell2\"></a>\n",
    "# 2. Data wrangling\n",
    "\n",
    "## Encoding categorical features\n",
    "\n",
    "Most machine learning models expect the features to be continuous numerical variables. In addition, the last time I checked, Scikit-learn makes this mandatory. However, our features are all categorical variables! This means we'll need to encode them with numbers so we can perform the math required to train a classifier. \n",
    "\n",
    "One encoding option is to convert the distinct values for each feature into integers (`LabelEncoder` from Scikit-learn is handy). For example, the values for `veil color` are brown, orange, white, and yellow, but they can be represented by 1, 2, 3 and 4, respectively. Unfortunately, this is strategy has nonsensical implications&mdash; yellow isn't four times the value of brown! Now if our features were *ordinal* categorical variables, such as T-shirt size (small, medium, large), this strategy could have worked.\n",
    "\n",
    "Instead, our features are *nominal* categorical variables with no intrinsic order. Therefore, we'll need to perform **one-hot encoding**, in which each  feature with $z$ possible values is converted into $z$ binary features, only one of which is \"on\". We could use `OneHotEncoder` from Scikit-learn to execute this strategy, but this preprocessor requires the categories to be already encoded as integers. We can actually skip this extra step if we instead use `get_dummies()` from Pandas, which does everything in one go and provides appropriate column labels to boot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap shape_b</th>\n",
       "      <th>cap shape_c</th>\n",
       "      <th>cap shape_f</th>\n",
       "      <th>cap shape_k</th>\n",
       "      <th>cap shape_s</th>\n",
       "      <th>cap shape_x</th>\n",
       "      <th>cap surface_f</th>\n",
       "      <th>cap surface_g</th>\n",
       "      <th>cap surface_s</th>\n",
       "      <th>cap surface_y</th>\n",
       "      <th>...</th>\n",
       "      <th>population_n</th>\n",
       "      <th>population_s</th>\n",
       "      <th>population_v</th>\n",
       "      <th>population_y</th>\n",
       "      <th>habitat_d</th>\n",
       "      <th>habitat_g</th>\n",
       "      <th>habitat_l</th>\n",
       "      <th>habitat_m</th>\n",
       "      <th>habitat_p</th>\n",
       "      <th>habitat_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap shape_b  cap shape_c  cap shape_f  cap shape_k  cap shape_s  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            1            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   cap shape_x  cap surface_f  cap surface_g  cap surface_s  cap surface_y  \\\n",
       "0            1              0              0              1              0   \n",
       "1            1              0              0              1              0   \n",
       "2            0              0              0              1              0   \n",
       "3            1              0              0              0              1   \n",
       "4            1              0              0              1              0   \n",
       "\n",
       "     ...      population_n  population_s  population_v  population_y  \\\n",
       "0    ...                 0             1             0             0   \n",
       "1    ...                 1             0             0             0   \n",
       "2    ...                 1             0             0             0   \n",
       "3    ...                 0             1             0             0   \n",
       "4    ...                 0             0             0             0   \n",
       "\n",
       "   habitat_d  habitat_g  habitat_l  habitat_m  habitat_p  habitat_u  \n",
       "0          0          0          0          0          0          1  \n",
       "1          0          1          0          0          0          0  \n",
       "2          0          0          0          1          0          0  \n",
       "3          0          0          0          0          0          1  \n",
       "4          0          1          0          0          0          0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding of each feature\n",
    "X_enc = pd.get_dummies(X)\n",
    "\n",
    "# Display the first five rows\n",
    "X_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing one-hot encoding, we also dramatically expanded the feature space from 22 to 98. This is concerning because we're increasing the likelihood of overfitting when we train a model. Let's keep an eye out for this issue when we evaluate the performance of the classifier.\n",
    "\n",
    "## Standardizing the features\n",
    "\n",
    "Some machine learning algorithms, such as principal components analysis, only work if the features are standardized to have zero mean and unit variance; others will converge faster. Only tree-based models see no real benefit from feature standardization, but in general, it doesn't hurt to standardize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the target variable\n",
    "\n",
    "Some machine learning classifiers in Scikit-learn [prefer](https://stats.stackexchange.com/questions/134427/in-practice-why-do-we-convert-categorical-class-labels-to-integers-for-classifi) that the class labels in the target variable are encoded with numbers. Since we only have two classes, we can use `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the class labels in the target variable\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell3\"></a>\n",
    "# 3. Training a model with the hold-out method\n",
    "\n",
    "I like to use the [law of parsimony](https://en.wikipedia.org/wiki/Occam%27s_razor) when solving problems; this includes the selection of machine learning models. Therefore, we'll begin with a [logistic regression classifier](http://inmachineswetrust.com/posts/building-logistic-regression/) and go from there.\n",
    "\n",
    "For a quick and dirty analysis, we'll use the holdout method (80/20 training and test split) to gauge how well the classifier is performing. As we had discovered the classes are imbalanced, we'll need to incorporate **stratification** to retain the same class distribution within the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the training and test sets using an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_std,\n",
    "    y_enc,\n",
    "    test_size=0.2,\n",
    "    stratify=y_enc,\n",
    "    random_state=42    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a logistic regression classifier on the training set using the default hyperparameter ($L_2$ regularization, $\\lambda = 1$) and evaluate its performance on the test set. Because the classes are imbalanced, we need to use a performance metric other than classification accuracy; the [$F_1$ score](https://en.wikipedia.org/wiki/F1_score) should do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression classifer using the training set\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the F1 score\n",
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the classifier has a perfect $F_1$ score on the test set, but keep in mind **this is just a single training/test split**; we need to confirm this performance holds for other splits. In addition, we need to tune the regularization hyperparameter. Fortunately, there's a way to tackle both at the same time without introducing additional bias.\n",
    "\n",
    "<a id=\"cell4\"></a>\n",
    "# 4. Using nested cross-validation to evaluate performance\n",
    "\n",
    "Instead of using the same data to tune the hyperparameter *and* evaluate model performance, we'll utilize [nested cross-validation](https://www.quora.com/I-train-my-system-based-on-the-10-fold-cross-validation-framework-Now-it-gives-me-10-different-models-Which-model-to-select-as-a-representative) to avoid risking optimistically biasing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a range of values to test the regularization hyperparameter\n",
    "param_grid = [{'C': np.logspace(-3, 3, 10)}]\n",
    "\n",
    "# Inner cross-validation loop to tune the hyperparameter\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Outer cross-validation loop to assess model performance\n",
    "scores = cross_val_score(\n",
    "    estimator=grid_search,\n",
    "    X=X_std,\n",
    "    y=y_enc,\n",
    "    cv=StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One downside to using nested cross-validation is how computationally intensive it can be. The outer loop splits the data into training/test folds using 10-fold cross-validation and reports model performance, while the inner loop performs a grid search on each training fold of the outer loop to tune the hyperparameter with 10-fold cross-validation. In addition, each grid search tests 10 hyperparameter values. That means we've just trained *1000 models!* Fortunately, `n_jobs=-1` parallelizes the operations across all CPU cores and speeds up the computation considerably.\n",
    "\n",
    "Let's take a look at model performance on each of the 10 test folds from the outer loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.99767442,  1.        ,  1.        ,  0.99767442,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Witnessing how consistent the performance is, we can now conclude the model is indeed performing well and not overfitting. This kind of stellar performance with a linear model, such as logistic regression, hints that **the relationship between our features and the target variable is simplistic and highly linear**. There's really no need to train a more complex machine learning model. Lastly, let's report the mean score as the final measure of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99953488372093025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell5\"></a>\n",
    "# 5. Identifying the most influential features\n",
    "\n",
    "All that remains is to train the model on the *entire* dataset so it can be deployed. But first, we need to perform grid search once more to identify the optimal regularization hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.10000000000000001}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the optimal regularization hyperparameter\n",
    "grid_search.fit(X_std, y_enc)\n",
    "\n",
    "# Display the hyperparameter value\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this hyperparameter value, let's train the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a logistic regression classifer using the entire dataset\n",
    "final_clf = LogisticRegression(C=0.1)\n",
    "final_clf.fit(X_std, y_enc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's report the five features that are most strongly correlated with class, either positively or negatively, as determined by the magnitude of the  learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>odor_p</th>\n",
       "      <td>1.078392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor_f</th>\n",
       "      <td>0.924890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore print color_h</th>\n",
       "      <td>0.924890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor_c</th>\n",
       "      <td>0.880472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore print color_r</th>\n",
       "      <td>0.577942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     parameter value\n",
       "odor_p                      1.078392\n",
       "odor_f                      0.924890\n",
       "spore print color_h         0.924890\n",
       "odor_c                      0.880472\n",
       "spore print color_r         0.577942"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the corresponding feature names to the parameters\n",
    "feature_ranks = pd.DataFrame(final_clf.coef_, index=['parameter value'])\n",
    "feature_ranks.columns = X_enc.columns\n",
    "\n",
    "# Display the five features most positively correlated with class\n",
    "feature_ranks.sort_values('parameter value', axis=1, ascending=False).T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>odor_n</th>\n",
       "      <td>-1.043962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor_l</th>\n",
       "      <td>-0.553868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor_a</th>\n",
       "      <td>-0.553868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk root_c</th>\n",
       "      <td>-0.481090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore print color_n</th>\n",
       "      <td>-0.448844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     parameter value\n",
       "odor_n                     -1.043962\n",
       "odor_l                     -0.553868\n",
       "odor_a                     -0.553868\n",
       "stalk root_c               -0.481090\n",
       "spore print color_n        -0.448844"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the five features most negatively correlated with class\n",
    "feature_ranks.sort_values('parameter value', axis=1, ascending=True).T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! It looks like the mushroom's odor is a predominant factor in determining whether it's edible.\n",
    "\n",
    "We can now use our model to decide if an *Agaricus* or *Lepiota* mushroom is edible. Evidently, this problem was a cakewalk for our machine learning model. Actually, I was hoping to find a dataset that would put up more of a challenge and allow me to troubleshoot the model, but it was still great for practicing with Scikit-learn. Nevertheless, this was a phenomenal example to showcase the power of machine learning&mdash;while experts concluded there is no rule that can be used to determine if these genera of mushrooms are edible, a machine with no domain knowledge figured it out without breaking a sweat! \n",
    "\n",
    "Nevertheless, **this model serves to assist experts, not replace them**. False negatives in this model may be life-threatening; as such, the final word about consuming a wild mushroom should always come from an expert.\n",
    "\n",
    "If you have any comments, questions or suggestions, kindly visit the [blog post](http://inmachineswetrust.com/posts/mushroom-classification/) associated with this analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
